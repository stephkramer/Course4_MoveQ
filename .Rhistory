# simulate trend or load data:
seq_data  <- seq(from = 0, to = 1, by=0.01)
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.7)
plot(x = seq_data, y = trend_data, pch = 15)
# analyse data - fit a logistic regression model with bionmial error structure
my.lm <- glm(formula = trend_data ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.lm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.lm$coefficients[[1]]
myslope     <- my.lm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.7
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend or load data:
seq_data  <- seq(from = 0, to = 1, by=0.05)
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.7)
plot(x = seq_data, y = trend_data, pch = 15)
# analyse data - fit a logistic regression model with bionmial error structure
my.lm <- glm(formula = trend_data ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.lm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.lm$coefficients[[1]]
myslope     <- my.lm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.7
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend or load data:
seq_data  <- seq(from = 0, to = 1, by=0.01)
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.7)
plot(x = seq_data, y = trend_data, pch = 15)
# analyse data - fit a logistic regression model with binomial error structure
my.lm <- glm(formula = trend_data ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.lm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.lm$coefficients[[1]]
myslope     <- my.lm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.7
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
?bern
?dbern
dbern(1,0.7)
??dbern
install.packages(purrr)
trend_data_binom <- purrr::dbernoulli(length(seq_data),0.7)
trend_data_binom <- purrr::rbernoulli(length(seq_data),0.7)
trend_data_binom
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data_binom, pch = 15)
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data_binom, pch = '|')
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.01) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.7)
plot(x = seq_data, y = trend_data, pch = 15)
# now we have to convert the trend_data line into 0 or 1 (a Bernoulli trial)
# depending on the underlying forest percentage (seq_data).
# The trend_data_binom are absence (0) or presence (1) of the species depending
# on the surrounding forest percentage
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data_binom, pch = '|')
# analyse data - fit a logistic regression model with binomial error structure
my.glm <- glm(formula = trend_data_binom ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.glm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.glm$coefficients[[1]]
myslope     <- my.glm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.7
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.01) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.5)
plot(x = seq_data, y = trend_data, pch = 15)
# now we have to convert the trend_data line into 0 or 1 (a Bernoulli trial)
# depending on the underlying forest percentage (seq_data).
# The trend_data_binom are absence (0) or presence (1) of the species depending
# on the surrounding forest percentage
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data_binom, pch = '|')
# analyse data - fit a logistic regression model with binomial error structure
my.glm <- glm(formula = trend_data_binom ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.glm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.glm$coefficients[[1]]
myslope     <- my.glm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.7
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.05) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.5)
plot(x = seq_data, y = trend_data, pch = 15)
# now we have to convert the trend_data line into 0 or 1 (a Bernoulli trial)
# depending on the underlying forest percentage (seq_data).
# The trend_data_binom are absence (0) or presence (1) of the species depending
# on the surrounding forest percentage
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data_binom, pch = '|')
# analyse data - fit a logistic regression model with binomial error structure
my.glm <- glm(formula = trend_data_binom ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.glm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.glm$coefficients[[1]]
myslope     <- my.glm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.5
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.05) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.7)
plot(x = seq_data, y = trend_data, pch = 15)
# now we have to convert the trend_data line into 0 or 1 (a Bernoulli trial)
# depending on the underlying forest percentage (seq_data).
# The trend_data_binom are absence (0) or presence (1) of the species depending
# on the surrounding forest percentage
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data_binom, pch = '|')
# analyse data - fit a logistic regression model with binomial error structure
my.glm <- glm(formula = trend_data_binom ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.glm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.glm$coefficients[[1]]
myslope     <- my.glm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.5
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.05) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
# now we have to convert the trend_data line into 0 or 1 (a Bernoulli trial)
# depending on the underlying forest percentage (seq_data).
# The trend_data_binom are absence (0) or presence (1) of the species depending
# on the surrounding forest percentage
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data_binom, pch = '|')
# analyse data - fit a logistic regression model with binomial error structure
my.glm <- glm(formula = trend_data_binom ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.glm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.glm$coefficients[[1]]
myslope     <- my.glm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
# ...or predict it only for a single value:
myvalue <- 0.5
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.05) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.01) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.05) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.01) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.05) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.02) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.03) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
# define functions at the beginning of a script:
f_logit <- function(var1, intcpt, slp) {intcpt + (slp * var1)}
f_prob  <- function(var2) {1 / (1 + exp(x = -var2))} #inverse logit
# simulate trend, i.e. the 'real' relationship:
seq_data  <- seq(from = 0, to = 1, by=0.01) # e.g. forest percentage
trend_data <- pbinom(q = 1:length(seq_data), size = length(seq_data), prob = 0.6)
plot(x = seq_data, y = trend_data, pch = 15)
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
my.glm <- glm(formula = trend_data_binom ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.glm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.glm$coefficients[[1]]
myslope     <- my.glm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2) #fitted model
points(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
myvalue <- 0.5
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2) # fitted model
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
# <function_name> or <function_name>() shows the function
citation() # how to cite R
?citation() # getting help use ? (or??) or
help(citation)
# <function_name> or <function_name>() shows the function
citation() # how to cite R
?citation() # getting help use ? (or??) or
help(citation)
# <function_name> or <function_name>() shows the function
citation() # how to cite R
?citation() # getting help use ? (or??) or
help(citation)
install.packages("formatR")
library(formatR)
# install.packages(purrr) # in case the package is not installed
set.seed(500) # ignore this line
trend_data_binom <- purrr::rbernoulli(length(seq_data),trend_data)
plot(x = seq_data, y = trend_data, pch = 15, col = 'grey')
points(x = seq_data, y = trend_data_binom, pch = '|')
my.glm <- glm(formula = trend_data_binom ~ seq_data, family = 'binomial', na.action = na.omit)
summary(my.glm)
# store the output; access my.lm object via:
#str(my.lm)
myintercept <- my.glm$coefficients[[1]]
myslope     <- my.glm$coefficients[[2]]
# predict it for a certain range of variable values (seq_data)...
mylogit   <- f_logit(var1 = seq_data, intcpt = myintercept, slp = myslope)
pres_prob <- f_prob(var2 = mylogit)
# strictly linear relationship on the logit scale:
plot(x = seq_data, y = mylogit, type = 'l', lwd = 2)
# on the response / inverse logit scale:
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2)
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2) # fitted model
lines(x = seq_data, y = trend_data, pch = 15, col = 'grey') # 'true' distribution
points(x = seq_data, y = trend_data_binom, pch = '|') #field sampling based on 'true' distribution
myvalue <- 0.55
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2) # fitted model
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
myvalue <- 0.5
mylogit_s   <- f_logit(var1 = myvalue, intcpt = myintercept, slp = myslope)
(pres_prob_s <- f_prob(var2 = mylogit_s))
plot(x = seq_data, y = pres_prob, type = 'l', lwd = 2) # fitted model
abline(v=myvalue, lty=2,lwd=0.1)
abline(h=pres_prob_s, lty=2,lwd=0.1)
round(pres_prob_s * 100,digits=2)
unique(dat_anim_na$yearday)
table(dat_anim_na$yearday) #######there is a strange date 26.12.2025!!!!!!!!!! omit!
dat_anim_na$date    <- ymd(dat_anim_na$start.timestamp)
?ymc
?ymd
dat_anim_na$date    <- date(dat_anim_na$start.timestamp)
dat_anim_na$date
unique(dat_anim_na$date)
table(dat_anim_na$date)
LocPDay <- as.data.frame(table(dat_anim_na$date))
barplot(LocPDay$Freq,axes = T,width=0.5)
axis(1, at= 1:nrow(LocPDay), labels = LocPDay[,1],las=2)
length(table(dat_anim_na$date))
delme <- which(dat_anim_na$date == '2025-12-26')
dat_anim_na[delme,]
plot(table(dat_anim_na$date))
table(dat_anim_na$date)  #  there is a strange date - 2025-12-26
# Delete data row
delme <- which(dat_anim_na$date == '2025-12-26')
dat_anim_na[delme,]
dat_anim_na <- dat_anim_na[-delme,] # delete the strange date and
table(dat_anim_na$date)             # check again
plot(table(dat_anim_na$date))       # plot the number of fixes per day
plot(table(dat_anim_na$hour))       # plot the number of fixes per hour
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
timetoplot
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
plot.circular(timetoplot, stack=TRUE, shrink=2, cex=0.7,col="red")
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
plot.circular(timetoplot, stack=TRUE, shrink=1, cex=0.7,col="red")
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
plot.circular(timetoplot, stack=TRUE, shrink=1, cex=0.1,col="red")
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
plot.circular(timetoplot, stack=TRUE, shrink=5, cex=0.7,col="red")
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
plot.circular(timetoplot, stack=F, shrink=5, cex=0.7,col="red")
# simpler alternative - plot events on a circle
timetoplot <- circular(dat_anim_na$hour%%24, # convert to 24 hrs
units="hours", template="clock24")
plot.circular(timetoplot, stack=F, shrink=1, cex=0.7,col="red")
rose.diag(timetoplot, bin=24, col="blue",
main="Events by Hour (sqrt scale)", prop=3)
rose.diag(timetoplot, bin=24, col="blue",
main="Events by Hour (linear scale)", prop=10,
radii.scale = "linear")
rp <- rose.diag(timetoplot, bin=24, col="blue",
main="Events by Hour (sqrt scale)", prop=3)
points(timetoplot, plot.info=rp, col="purple",stack=TRUE)
rose.diag(timetoplot, bin=24, col="blue",
main="Events by Hour (sqrt scale)", prop=3)
rose.diag(timetoplot, bin=24, col="blue",
main="Events by Hour (sqrt scale)", prop=5)
rose.diag(timetoplot, bin=24, col="blue",
main="Events by Hour (linear scale)", prop=10,
radii.scale = "linear")
rose.diag(timetoplot, bin=24, col="blue",
main="Events by Hour (sqrt scale)", prop=3)
# with ggplot
ggplot(dat_anim_na,aes(x=hour,fill=daytime))+
geom_bar(breaks=seq(0,24),width = 2,colour="grey")+
coord_polar(start=0)+
theme_minimal()+
scale_fill_brewer()+
ylab("Count")+
ggtitle("Events by Time of day")+
scale_x_continuous("", limits=c(0,24),
breaks=seq(0,24),
labels=seq(0,24))
# R data file - can only be opened/ read with R by using function load()
save(dat_anim_na, file = here('output/data-proc/tag5334_gps_proc.rda'))
# interchange file format .csv
write.csv(dat_anim_na, file = here('output/data-proc/tag5334_gps_proc.csv'))
animal <- load(file = here('output/data-proc/tag5334_gps_proc.rda'))
animal
rm(dat_anim_na)
dat_anim_na
load(file = here('output/data-proc/tag5334_gps_proc.rda'))
baseplot_df <- ggplot(data = dat_anim_na) +
geom_point(aes(x=longitude,
y=latitude,
color = daytime),
size=0.01, alpha=0.5)   +
xlab("Longitude") + ylab("Latitude") +
ggtitle("Telemetry data") + theme_bw()
baseplot_df
baseplot_sf <- ggplot(data = mydf_sf_trans) +
geom_sf(aes(color = daytime),size=0.01, alpha=0.5)   +
xlab("Longitude") + ylab("Latitude") +
ggtitle("Telemetry data") + theme_bw()
baseplot_sf
# R data file - can only be opened/ read with R by using function load()
saveRDS(dat_anim_na, file = here('output/data-proc/tag5334_gps_proc.Rds'))
# interchange file format .csv
write.csv(dat_anim_na, file = here('output/data-proc/tag5334_gps_proc.csv'))
animal <- readRDS(file = here('output/data-proc/tag5334_gps_proc.Rds'))
animal
here
here()
